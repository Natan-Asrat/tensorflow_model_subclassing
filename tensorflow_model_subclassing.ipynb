{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model subclassing and custom training loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Coding tutorials\n",
    " #### [1. Model subclassing](#coding_tutorial_1)\n",
    " #### [2. Custom layers](#coding_tutorial_2)\n",
    " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
    " #### [4. Custom training loops](#coding_tutorial_4)\n",
    " #### [5. tf.function decorator](#coding_tutorial_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## Model subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a simple model using the model subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense_1 = Dense(64, activation='relu')\n",
    "        self.dense_2 = Dense(10)\n",
    "        self.dropout = Dropout(0.4)\n",
    "        self.dense_3 = Dense(5)\n",
    "        self.softmax = Softmax()\n",
    "    def call(self, inputs, training=True):\n",
    "        x = self.dense_1(inputs)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        y1 = self.dense_2(inputs)\n",
    "        y2 = self.dense_3(y1)\n",
    "        concat = concatenate([x, y2])\n",
    "        return self.softmax(concat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              multiple                  704       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              multiple                  110       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             multiple                  55        \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 869\n",
      "Trainable params: 869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "model = MyModel()\n",
    "model(tf.random.uniform([1,10]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.0626193   0.04913922  0.12365119]], shape=(1, 3), dtype=float32)\n",
      "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
      "array([[-0.04134676, -0.04231959, -0.04898072],\n",
      "       [-0.03789784,  0.04615932,  0.0651149 ],\n",
      "       [ 0.06392324,  0.00828658,  0.01372161],\n",
      "       [-0.02540391, -0.00353492, -0.05137044],\n",
      "       [-0.02189403,  0.04054783,  0.14516585]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# Create a custom layer\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_dim, units),\n",
    "            initializer='random_normal'\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(units,),\n",
    "            initializer='zeros'\n",
    "        )\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "dense_layer = MyLayer(3,5)\n",
    "x = tf.ones((1,5))\n",
    "print(dense_layer(x))\n",
    "print(dense_layer.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 0.09195492 -0.12185975  0.09816701]], shape=(1, 3), dtype=float32)\n",
      "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
      "array([[-0.02093339,  0.02247063, -0.0190374 ],\n",
      "       [ 0.06625366, -0.02236561,  0.06392977],\n",
      "       [ 0.07652761,  0.0432266 , -0.00890184],\n",
      "       [-0.00289931, -0.0302312 ,  0.0388661 ],\n",
      "       [-0.02699365, -0.13496016,  0.02331039]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# Specify trainable weights\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_dim, units),\n",
    "            initializer='random_normal',\n",
    "            trainable=False\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(units,),\n",
    "            initializer='zeros',\n",
    "            trainable=False\n",
    "        )\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "dense_layer = MyLayer(3,5)\n",
    "x = tf.ones((1,5))\n",
    "print(dense_layer(x))\n",
    "print(dense_layer.weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable weights: 0\n",
      "non-trainable weights: 2\n"
     ]
    }
   ],
   "source": [
    "print('trainable weights:', len(dense_layer.trainable_weights))\n",
    "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom layer to accumulate means of output values\n",
    "\n",
    "\n",
    "class MyLayerMean(Layer):\n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayerMean, self).__init__()\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_dim, units),\n",
    "            initializer='random_normal'\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(units,),\n",
    "            initializer='zeros'\n",
    "        )\n",
    "        self.sum_activation = tf.Variable(\n",
    "            initial_value=tf.zeros((units,)),\n",
    "            trainable=False\n",
    "        )\n",
    "        self.number_call = tf.Variable(\n",
    "            initial_value=0,\n",
    "            trainable=False\n",
    "        )\n",
    "    def call(self, inputs):\n",
    "        activations =  tf.matmul(inputs, self.w) + self.b\n",
    "        self.sum_activation.assign_add(tf.reduce_sum(activations, axis=0))\n",
    "        self.number_call.assign_add(inputs.shape[0])\n",
    "        return activations , self.sum_activation/tf.cast(\n",
    "            self.number_call, tf.float32\n",
    "        )\n",
    "        \n",
    "dense_layer = MyLayerMean(3,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.16241717  0.03885861 -0.07925268]\n",
      "[ 0.16241717  0.03885861 -0.07925268]\n",
      "[ 0.16241717  0.03885861 -0.07925268]\n"
     ]
    }
   ],
   "source": [
    "# Test the layer\n",
    "\n",
    "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
    "print(activation_means.numpy())\n",
    "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
    "print(activation_means.numpy())\n",
    "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
    "print(activation_means.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dropout layer as a custom layer\n",
    "\n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, rate=self.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the custom layers into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model using custom layers with the model subclassing API\n",
    "\n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2, units_1)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.softmax = Softmax()\n",
    "        self.layer_3 = MyLayer(units_3, units_2)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.00539661 0.02554333 0.02299581 0.01188668 0.02844253 0.01166078\n",
      "  0.03007986 0.02522258 0.03032939 0.0598928  0.00473409 0.00477827\n",
      "  0.01372864 0.01090466 0.01543228 0.00816004 0.01106479 0.01986442\n",
      "  0.00597739 0.0448938  0.01206553 0.00579108 0.01594382 0.00501296\n",
      "  0.02630203 0.00738529 0.02409104 0.05282146 0.01525156 0.00642285\n",
      "  0.01282337 0.01533479 0.01936935 0.01393618 0.00586043 0.01023527\n",
      "  0.01460242 0.01851021 0.0473729  0.01367412 0.12012313 0.02886706\n",
      "  0.03209867 0.03790056 0.01855402 0.02866118]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer_11 (MyLayer)        multiple                  640064    \n",
      "_________________________________________________________________\n",
      "my_dropout_4 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_12 (MyLayer)        multiple                  4160      \n",
      "_________________________________________________________________\n",
      "my_dropout_5 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "softmax_4 (Softmax)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_13 (MyLayer)        multiple                  2990      \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 0\n",
      "Non-trainable params: 647,214\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a model object\n",
    "\n",
    "model = MyModel(64,10000,64,46)\n",
    "print(model(tf.ones((1, 10000))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## Automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7b96f8d36710>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create data from a noise contaminated linear model\n",
    "\n",
    "def MakeNoisyData(m, b, n=20):\n",
    "    x = tf.random.uniform(shape=(n,))\n",
    "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
    "    y = m * x + b + noise\n",
    "    return x, y\n",
    "\n",
    "m=1\n",
    "b=2\n",
    "x_train, y_train = MakeNoisyData(m,b)\n",
    "plt.plot(x_train, y_train, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.00168511 0.00133037 0.00135145 0.00126597 0.00103829 0.00035574\n",
      " 0.00124139 0.00124822 0.00177736 0.00066039 0.0008154  0.00049441\n",
      " 0.00044066 0.00194889 0.00010194 0.00146942 0.00081883 0.00176132\n",
      " 0.00063391 0.00044116], shape=(20,), dtype=float32)\n",
      "[<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.0019494], dtype=float32)>, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# Build a custom layer for the linear regression model\n",
    "\n",
    "class LinearLayer(Layer):\n",
    "    def __init__(self):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        self.m = self.add_weight(\n",
    "            shape=(1,),\n",
    "            initializer = 'random_normal'\n",
    "            \n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(1,),\n",
    "            initializer='zeros'\n",
    "        )\n",
    "    def call(self, inputs):\n",
    "        return self.m*inputs + self.b\n",
    "    \n",
    "linear_regression = LinearLayer()\n",
    "print(linear_regression(x_train))\n",
    "print(linear_regression.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss 6.594203\n"
     ]
    }
   ],
   "source": [
    "# Define the mean squared error loss function\n",
    "\n",
    "def SquaredError(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
    "\n",
    "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
    "print(\"Starting loss\", starting_loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 , loss 4.990361213684082\n",
      "step 1 , loss 3.777508497238159\n",
      "step 2 , loss 2.8603289127349854\n",
      "step 3 , loss 2.166741132736206\n",
      "step 4 , loss 1.642237663269043\n",
      "step 5 , loss 1.2455984354019165\n",
      "step 6 , loss 0.945652186870575\n",
      "step 7 , loss 0.7188268303871155\n",
      "step 8 , loss 0.5472968220710754\n",
      "step 9 , loss 0.4175819456577301\n",
      "step 10 , loss 0.3194883167743683\n",
      "step 11 , loss 0.2453073263168335\n",
      "step 12 , loss 0.18920950591564178\n",
      "step 13 , loss 0.14678636193275452\n",
      "step 14 , loss 0.11470429599285126\n",
      "step 15 , loss 0.09044230729341507\n",
      "step 16 , loss 0.07209403067827225\n",
      "step 17 , loss 0.05821780487895012\n",
      "step 18 , loss 0.047723449766635895\n",
      "step 19 , loss 0.039786484092473984\n",
      "step 20 , loss 0.033783506602048874\n",
      "step 21 , loss 0.029243022203445435\n",
      "step 22 , loss 0.025808533653616905\n",
      "step 23 , loss 0.0232104305177927\n",
      "step 24 , loss 0.021244807168841362\n"
     ]
    }
   ],
   "source": [
    "# Implement a gradient descent training loop for the linear regression model\n",
    "\n",
    "learning_rate = 0.05\n",
    "steps = 25\n",
    "\n",
    "for i in range(steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = linear_regression(x_train)\n",
    "        loss = SquaredError(predictions, y_train)\n",
    "    gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
    "    linear_regression.m.assign_sub(learning_rate*gradients[0])\n",
    "    linear_regression.b.assign_sub(learning_rate*gradients[1])\n",
    "    print(f\"step {i} , loss {loss.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:1,  trained m:[1.0707662]\n",
      "b:2,  trained b:[1.9078482]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7b96f8caf5c0>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learned regression model\n",
    "\n",
    "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
    "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
    "\n",
    "plt.plot(x_train, y_train, 'b.')\n",
    "\n",
    "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
    "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## Custom training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.03403839 0.04629086 0.02412183 0.00798402 0.02749479 0.06137826\n",
      "  0.02082365 0.04025724 0.01548414 0.00503814 0.00819041 0.02761841\n",
      "  0.02867912 0.01668907 0.00695163 0.01200212 0.01213399 0.01129864\n",
      "  0.03582716 0.02535176 0.01447437 0.00768772 0.01990999 0.0216886\n",
      "  0.01719938 0.04320511 0.00750087 0.00998435 0.01644506 0.01905583\n",
      "  0.03673537 0.0178395  0.01587201 0.00434333 0.02761361 0.00737691\n",
      "  0.01266211 0.02451047 0.04199854 0.01169264 0.01368847 0.01814175\n",
      "  0.02174503 0.03875251 0.04292514 0.01929763]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer_20 (MyLayer)        multiple                  640064    \n",
      "_________________________________________________________________\n",
      "my_dropout_10 (MyDropout)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_21 (MyLayer)        multiple                  4160      \n",
      "_________________________________________________________________\n",
      "my_dropout_11 (MyDropout)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "softmax_7 (Softmax)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_22 (MyLayer)        multiple                  2990      \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 647,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the custom layers and model\n",
    "\n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, rate=self.rate)\n",
    "class MyLayer(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.units = units\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer='random_normal',\n",
    "            name=\"kernel\"\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,),\n",
    "            initializer='zeros',\n",
    "            name=\"bias\"\n",
    "        )\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "# Build the model using custom layers with the model subclassing API\n",
    "\n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layer_1 = MyLayer(units_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.softmax = Softmax()\n",
    "        self.layer_3 = MyLayer(units_3)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        return self.softmax(x)\n",
    "    \n",
    "model = MyModel(64, 64, 46)\n",
    "print(\n",
    "    model(\n",
    "        tf.ones(\n",
    "            (1,10000)\n",
    "        )\n",
    "    ))\n",
    "print(model.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the reuters dataset and define the class_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "\n",
    "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: earn\n"
     ]
    }
   ],
   "source": [
    "# Print the class of the first sample\n",
    "\n",
    "print(\"Label: {}\".format(class_names[train_labels[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the dataset word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Reuters word index\n",
    "\n",
    "word_to_index = reuters.get_word_index()\n",
    "\n",
    "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
    "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# Print the first data example sentence\n",
    "\n",
    "print(text_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (8982, 10000)\n",
      "Shape of x_test: (2246, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Define a function that encodes the data into a 'bag of words' representation\n",
    "\n",
    "def bag_of_words(text_samples, elements=10000):\n",
    "    output = np.zeros((len(text_samples), elements))\n",
    "    for i, word in enumerate(text_samples):\n",
    "        output[i, word] = 1.\n",
    "    return output\n",
    "\n",
    "x_train = bag_of_words(train_data)\n",
    "x_test = bag_of_words(test_data)\n",
    "\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function and optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical cross entropy loss and Adam optimizer\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "def loss(model, x, y, wd):\n",
    "    kernel_variables = []\n",
    "    for l in model.layers:\n",
    "        for w in l.weights:\n",
    "            if 'kernel' in w.name:\n",
    "                kernel_variables.append(w)\n",
    "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
    "    y_ = model(x)\n",
    "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the forward and backward pass\n",
    "\n",
    "def grad(model, inputs, targets, wd):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, wd)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_model_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 0, Loss 2.429324150085449, Accuracy 0.5534402132034302 \n",
      "Epoch 1, Loss 1.9471075534820557, Accuracy 0.651970624923706 \n",
      "Epoch 2, Loss 1.8307054042816162, Accuracy 0.6765753626823425 \n",
      "Epoch 3, Loss 1.7958550453186035, Accuracy 0.6805834174156189 \n",
      "Epoch 4, Loss 1.7643563747406006, Accuracy 0.6889334321022034 \n",
      "Epoch 5, Loss 1.741506814956665, Accuracy 0.6923847794532776 \n",
      "Epoch 6, Loss 1.729645013809204, Accuracy 0.6965041160583496 \n",
      "Epoch 7, Loss 1.7118914127349854, Accuracy 0.7010688185691833 \n",
      "Epoch 8, Loss 1.708418369293213, Accuracy 0.7000668048858643 \n",
      "Epoch 9, Loss 1.7107535600662231, Accuracy 0.703406810760498 \n",
      "Duration :317.236\n"
     ]
    }
   ],
   "source": [
    "# Implement the training loop\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "start_time = time.time()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
    "train_dataset = train_dataset.batch(32)\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 10\n",
    "weight_decay=0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    \n",
    "    for x, y in train_dataset:\n",
    "        loss_value, grads = grad(model, x, y, weight_decay)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        epoch_loss_avg(loss_value)\n",
    "        epoch_accuracy(to_categorical(y), model(x))\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    print(f\"Epoch {epoch}, Loss {epoch_loss_avg.result()}, Accuracy {epoch_accuracy.result()} \")\n",
    "    \n",
    "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset object for the test set\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect average loss and accuracy\n",
    "\n",
    "epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.832\n",
      "Test accuracy: 67.231%\n"
     ]
    }
   ],
   "source": [
    "# Loop over the test set and print scores\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "for x, y in test_dataset:\n",
    "    # Optimize the model\n",
    "    loss_value = loss(model, x, y, weight_decay)    \n",
    "    # Compute current loss\n",
    "    epoch_loss_avg(loss_value)  \n",
    "    # Compare predicted label to actual label\n",
    "    epoch_accuracy(to_categorical(y), model(x))\n",
    "\n",
    "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
    "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training loss and accuracy\n",
    "\n",
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_accuracy_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: earn\n",
      "     Label: earn\n"
     ]
    }
   ],
   "source": [
    "# Get the model prediction for an example input\n",
    "\n",
    "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
    "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
    "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## tf.function decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import reuters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.02567469 0.01752379 0.00812103 0.0545858  0.01998338 0.01396912\n",
      "  0.03296261 0.00444086 0.04165715 0.01419044 0.02853787 0.02920461\n",
      "  0.0216879  0.02000885 0.01321448 0.02365802 0.01387166 0.00734468\n",
      "  0.0274634  0.0175691  0.02768187 0.03881757 0.00977128 0.00880201\n",
      "  0.02485166 0.03104315 0.00394652 0.09266939 0.00272467 0.01334097\n",
      "  0.00758833 0.02865852 0.02003206 0.01594587 0.02548526 0.01156143\n",
      "  0.00986421 0.04013818 0.00877991 0.00917307 0.03405224 0.0477905\n",
      "  0.00677008 0.02034623 0.00511471 0.01938079]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer (MyLayer)           multiple                  640064    \n",
      "_________________________________________________________________\n",
      "my_dropout (MyDropout)       multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_1 (MyLayer)         multiple                  4160      \n",
      "_________________________________________________________________\n",
      "my_dropout_1 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_2 (MyLayer)         multiple                  2990      \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 647,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Initialize a new model\n",
    "\n",
    "\n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, rate=self.rate)\n",
    "class MyLayer(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.units = units\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer='random_normal',\n",
    "            name=\"kernel\"\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,),\n",
    "            initializer='zeros',\n",
    "            name=\"bias\"\n",
    "        )\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "# Build the model using custom layers with the model subclassing API\n",
    "\n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layer_1 = MyLayer(units_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.softmax = Softmax()\n",
    "        self.layer_3 = MyLayer(units_3)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        return self.softmax(x)\n",
    "    \n",
    "model = MyModel(64, 64, 46)\n",
    "print(\n",
    "    model(\n",
    "        tf.ones(\n",
    "            (1,10000)\n",
    "        )\n",
    "    ))\n",
    "print(model.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefine the grad function using the @tf.function decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the @tf.function decorator\n",
    "\n",
    "@tf.function\n",
    "def grad(model, inputs, targets, wd):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, wd)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 0, Loss 3.3017711639404297, Accuracy 0.4915386438369751 \n",
      "Epoch 1, Loss 1.9167799949645996, Accuracy 0.615787148475647 \n",
      "Epoch 2, Loss 1.8132872581481934, Accuracy 0.6602092981338501 \n",
      "Epoch 3, Loss 1.774991750717163, Accuracy 0.6801380515098572 \n",
      "Epoch 4, Loss 1.748447060585022, Accuracy 0.6869294047355652 \n",
      "Epoch 5, Loss 1.7403656244277954, Accuracy 0.6948341131210327 \n",
      "Epoch 6, Loss 1.7320002317428589, Accuracy 0.7011801600456238 \n",
      "Epoch 7, Loss 1.7123242616653442, Accuracy 0.7035181522369385 \n",
      "Epoch 8, Loss 1.7269622087478638, Accuracy 0.706078827381134 \n",
      "Epoch 9, Loss 1.7138278484344482, Accuracy 0.7077488303184509 \n",
      "Duration :311.669\n"
     ]
    }
   ],
   "source": [
    "# Re-run the training loop\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "start_time = time.time()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
    "train_dataset = train_dataset.batch(32)\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 10\n",
    "weight_decay=0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    \n",
    "    for x, y in train_dataset:\n",
    "        loss_value, grads = grad(model, x, y, weight_decay)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        epoch_loss_avg(loss_value)\n",
    "        epoch_accuracy(to_categorical(y), model(x))\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    print(f\"Epoch {epoch}, Loss {epoch_loss_avg.result()}, Accuracy {epoch_accuracy.result()} \")\n",
    "    \n",
    "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the autograph code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__grad(model, inputs, targets, wd):\n",
      "  do_return = False\n",
      "  retval_ = ag__.UndefinedReturnValue()\n",
      "  with ag__.FunctionScope('grad', 'grad_scope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as grad_scope:\n",
      "    with tf.GradientTape() as tape:\n",
      "      loss_value = ag__.converted_call(loss, grad_scope.callopts, (model, inputs, targets, wd), None, grad_scope)\n",
      "    do_return = True\n",
      "    retval_ = grad_scope.mark_return_value((loss_value, ag__.converted_call(tape.gradient, grad_scope.callopts, (loss_value, model.trainable_variables), None, grad_scope)))\n",
      "  do_return,\n",
      "  return ag__.retval(retval_)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tf.autograph.to_code(grad.python_function))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
